import glob
import json
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0' 
from huggingface_hub import login
from typing import List
from src.rag_pipeline import RAGPipeline
from create_parser import create_parser

from src.impl import Datastore, Indexer, ResponseGenerator, Evaluator


DEFAULT_SOURCE_PATH = "sample_data/source/"
DEFAULT_EVAL_PATH = "sample_data/eval/sample_questions.json"
HF_TOKEN = ""


def main():
    parser = create_parser()  # Create the CLI parser
    args = parser.parse_args()
    pipeline = RAGPipeline()

    # Process source paths and eval path
    source_path = args.path if args.path else DEFAULT_SOURCE_PATH
    eval_path = args.eval_file if args.eval_file else DEFAULT_EVAL_PATH
    document_paths = get_files_in_directory(source_path)

    # Execute commands
    if args.command in ["reset", "run"]:
        print("ðŸ—‘ï¸  Resetting the database...")
        pipeline.reset()

    if args.command in ["add", "run"]:
        print(f"ðŸ” Adding documents: {', '.join(document_paths)}")
        pipeline.add_documents(document_paths)

    if args.command in ["evaluate", "run"]:
        print(f"ðŸ“Š Evaluating using questions from: {eval_path}")
        with open(eval_path, "r") as file:
            sample_questions = json.load(file)
        pipeline.evaluate(sample_questions)

    if args.command == "query":
        print(f"âœ¨ Response: {pipeline.process_query(args.prompt)}")


def get_files_in_directory(source_path: str) -> List[str]:
    if os.path.isfile(source_path):
        return [source_path]
    return glob.glob(os.path.join(source_path, "*"))


if __name__ == "__main__":
    login(token=HF_TOKEN)
    main()
